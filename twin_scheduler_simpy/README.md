# üè≠ Twin Scheduler SimPy - FASE 1 + FASE 2

## Descripci√≥n General

Proyecto integrado de simulaci√≥n Job Shop con dos fases:
- **Fase 1 (Est√°tico)**: Simulador determin√≠stico con reglas de despacho heur√≠sticas (SPT, EDD, LPT)
- **Fase 2 (Din√°mico)**: Simulador con llegadas din√°micas, fallos de m√°quinas y reparaciones

Ambas fases pueden ejecutarse **independientemente** o en **comparaci√≥n directa** usando instancias Taillard como datos compartidos.

### Caracter√≠sticas Implementadas (Fase 1)

‚úÖ **Simulador SimPy con m√°quinas y colas**
- M√°quinas como recursos con capacidad = 1
- Trabajos con operaciones en secuencia
- Buffers por m√°quina para las colas

‚úÖ **C√°lculo de M√©tricas**
- **Makespan**: Tiempo total de fabricaci√≥n
- **Tardanza**: Suma de atrasos respecto a fechas de entrega
- **VIP**: Work In Progress promedio
- **Utilizaci√≥n**: Porcentaje de ocupaci√≥n de m√°quinas

‚úÖ **Reglas de Despacho Implementadas**
- **SPT** (Shortest Processing Time): Trabajos cortos primero
- **EDD** (Earliest Due Date): Fecha de entrega m√°s temprana primero
- **LPT** (Longest Processing Time): Trabajos largos primero

‚úÖ **Datasets de Benchmark**
- **FT06**: 6 jobs √ó 6 m√°quinas (peque√±o, r√°pido)
- **FT10**: 10 jobs √ó 10 m√°quinas (mediano)

‚úÖ **Validaci√≥n y Reportes**
- Comparaci√≥n de rendimiento entre reglas
- Exportaci√≥n de logs en CSV
- Reportes formateados en consola

---

## Estructura de Archivos

```
twin_scheduler_simpy/
‚îú‚îÄ‚îÄ FASE 1: Simulador Est√°tico
‚îÇ   ‚îú‚îÄ‚îÄ simulator_static.py          # Simulador principal
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                    # C√°lculo de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ scheduling_rules.py           # Reglas de despacho (SPT, EDD, LPT)
‚îÇ   ‚îú‚îÄ‚îÄ datasets.py                   # Loader de datasets (FT06, FT10, Taillard)
‚îÇ
‚îú‚îÄ‚îÄ FASE 2: Simulador Din√°mico
‚îÇ   ‚îú‚îÄ‚îÄ simulator_dynamic.py          # Simulador con llegadas y fallos
‚îÇ   ‚îú‚îÄ‚îÄ arrival_generator.py          # Generador de llegadas (Poisson)
‚îÇ   ‚îú‚îÄ‚îÄ machine_failures.py           # Gestor de fallos (MTBF/MTTR)
‚îÇ   ‚îú‚îÄ‚îÄ event_manager.py              # Logger centralizado de eventos
‚îÇ
‚îú‚îÄ‚îÄ Integraci√≥n y Comparaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ main_comparison.py            # Script de comparaci√≥n Fase 1 vs Fase 2
‚îÇ   ‚îú‚îÄ‚îÄ taillard_integration.py       # Conversor Taillard -> llegadas escalonadas
‚îÇ   ‚îú‚îÄ‚îÄ taillard_loader.py            # Parser de instancias Taillard
‚îÇ
‚îú‚îÄ‚îÄ Datos y Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jobshop1.txt              # Instancias Taillard (abz5-abz9, ft06, ft10, etc.)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jobshop2.txt              # M√°s instancias Taillard
‚îÇ   ‚îú‚îÄ‚îÄ logs/                         # Logs y CSVs de simulaciones
‚îÇ   ‚îú‚îÄ‚îÄ README.md                     # Este archivo
‚îÇ   ‚îú‚îÄ‚îÄ PHASE1_SUMMARY.txt            # Resumen de Fase 1
‚îÇ   ‚îú‚îÄ‚îÄ PHASE2_SUMMARY.txt            # Resumen de Fase 2
‚îÇ
‚îú‚îÄ‚îÄ Infraestructura
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                   # M√≥dulo inicializador
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt              # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ venv/                         # Entorno virtual Python
‚îÇ   ‚îî‚îÄ‚îÄ tests/                        # Pruebas r√°pidas
‚îÇ       ‚îî‚îÄ‚îÄ test_taillard_load_and_run.py
```

---

## Instalaci√≥n

### 1. Crear y activar entorno virtual

```bash
cd c:\DEV\scheduling_marl_prototipo\twin_scheduler_simpy
python -m venv venv
venv\Scripts\activate
```

### 2. Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Dependencias

- **simpy**: 4.1.1 - Simulaci√≥n discreta de eventos
- **pandas**: 2.1.4 - An√°lisis y manipulaci√≥n de datos
- **numpy**: 1.26.3 - Computaci√≥n num√©rica

---

---

## Uso: Tres Modos de Ejecuci√≥n

### 1Ô∏è‚É£ FASE 1 SOLO (Simulador Est√°tico Independiente)

Para ejecutar **solo la Fase 1** sin Fase 2:

```bash
cd c:\DEV\scheduling_marl_prototipo\twin_scheduler_simpy
.venv\Scripts\python.exe simulator_static.py
```

Esto carga FT06 por defecto y ejecuta validaci√≥n con SPT, EDD, LPT.

**Salida:** Makespan, Tardanza, Utilizaci√≥n por m√°quina. Archivos CSV con logs.

### 2Ô∏è‚É£ FASE 2 SOLO (Simulador Din√°mico Independiente)

Para ejecutar **solo la Fase 2** con llegadas aleatorias y fallos:

```bash
cd c:\DEV\scheduling_marl_prototipo\twin_scheduler_simpy
.venv\Scripts\python.exe simulator_dynamic.py
```

Genera jobs con llegadas Poisson (Œª=0.4) y fallos de m√°quinas (MTBF=100, MTTR=8).

**Salida:** Eventos de llegada/falla/reparaci√≥n, downtime, disponibilidad. Archivos CSV.

### 3Ô∏è‚É£ COMPARACI√ìN COMPLETA (Fase 1 + Fase 2 con datos Taillard)

Para ejecutar **ambas fases juntas** con los mismos datos y obtener reporte comparativo:

```bash
cd c:\DEV\scheduling_marl_prototipo\twin_scheduler_simpy
.venv\Scripts\python.exe -m twin_scheduler_simpy.main_comparison
```

**Par√°metros opcionales:**

```bash
# Usar una instancia Taillard diferente
.venv\Scripts\python.exe -m twin_scheduler_simpy.main_comparison --dataset TA:datasets/jobshop1.txt:abz5 --rules SPT,EDD

# Cambiar MTBF y MTTR de Fase 2
.venv\Scripts\python.exe -m twin_scheduler_simpy.main_comparison --mtbf 200 --mttr 15

# Cambiar distribuci√≥n de llegadas escalonadas
.venv\Scripts\python.exe -m twin_scheduler_simpy.main_comparison --arrival-dist poisson
```

**Salida:** Tabla comparativa CSV con columnas:
- Regla | Makespan F1 | Makespan F2 | Delta Makespan | Tardanza F1 | Tardanza F2 | Delta Tardanza | Jobs Completados F2 | Downtime F2 | Disponibilidad F2

---

## Datasets Disponibles

### Datasets Integrados (Fase 1)
- **FT06**: 6 jobs √ó 6 m√°quinas (muy r√°pido)
- **FT10**: 10 jobs √ó 10 m√°quinas (r√°pido)

Uso:
```python
from datasets import Datasets
jobs, due_dates = Datasets.load_dataset("FT06")
jobs, due_dates = Datasets.load_dataset("FT10")
```

### Instancias Taillard (Fase 1 + Fase 2)
Archivos: `datasets/jobshop1.txt`, `datasets/jobshop2.txt`

Contienen ~80 instancias: abz5-abz9, ft06, ft10, ft20, la01-la40, orb01-orb10, swv01-swv20, yn1-yn4, ta01-ta80

Uso:
```python
from datasets import Datasets

# Cargar por √≠ndice (1-based)
jobs, due_dates = Datasets.load_dataset("TA:datasets/jobshop1.txt:1")     # Primera instancia

# Cargar por nombre
jobs, due_dates = Datasets.load_dataset("TA:datasets/jobshop1.txt:abz5")  # Instancia abz5
jobs, due_dates = Datasets.load_dataset("TA:datasets/jobshop1.txt:ft06")  # Instancia ft06

# En Fase 2 (comparaci√≥n)
python main_comparison.py --dataset TA:datasets/jobshop1.txt:abz5
```

---

## Uso Program√°tico

### Fase 1 (Est√°tico)

```python
from simulator_static import run_simulation, run_validation
from datasets import Datasets

# Validaci√≥n completa con FT06
results = run_validation(dataset_name="FT06", verbose=False)

# Simulaci√≥n individual
jobs, due_dates = Datasets.load_dataset("FT06")
result = run_simulation(jobs, due_dates, rule="SPT", verbose=True)
print(result["metrics"]["makespan"])
```

### Fase 2 (Din√°mico)

```python
import simpy
from simulator_dynamic import DynamicJobShopSimulator

env = simpy.Environment()
sim = DynamicJobShopSimulator(
    env=env,
    num_machines=6,
    arrival_rate=0.4,
    mtbf=100.0,
    mttr=8.0,
    scheduling_rule="SPT"
)
sim.run(until_time=1000.0)
sim.export_results()
```

### Comparaci√≥n (Ambas Fases)

```python
from main_comparison import run_phase1_batch, run_phase2_batch, generate_comparison_report
from datasets import Datasets

jobs, due_dates = Datasets.load_dataset("TA:datasets/jobshop1.txt:1")

# Fase 1
results_f1 = run_phase1_batch(jobs, due_dates, ["SPT", "EDD"])

# Fase 2
results_f2 = run_phase2_batch(jobs, due_dates, ["SPT", "EDD"])

# Reporte
df = generate_comparison_report(results_f1, results_f2, ["SPT", "EDD"])
print(df)
```


---

## Archivos Generados

Despu√©s de ejecutar la simulaci√≥n, se generan los siguientes archivos:

### üìä Logs de Simulaci√≥n
```
simulation_log_SPT_20251125_034202.csv
simulation_log_EDD_20251125_034202.csv
simulation_log_LPT_20251125_034202.csv
```

Formato:
```
time,event,job,machine
0.0,start,4,1
1.0,finish,4,1
1.0,start,4,2
...
```

### üìà Resultados Comparativos
```
validation_results_FT06_20251125_034202.csv
```

Formato:
```
Regla,Makespan,Tardanza Total,Tardanza Promedio,VIP,Utilizaci√≥n %
SPT,49.00,29.00,4.83,0.12,67.01
EDD,49.00,29.00,4.83,0.12,67.01
LPT,49.00,29.00,4.83,0.12,67.01
```

---

## Descripci√≥n de Clases

### `Machine`
Representa una m√°quina del job shop.

```python
machine = Machine(env, machine_id=0)
```

**Atributos:**
- `id`: Identificador √∫nico
- `resource`: Recurso SimPy (capacidad = 1)
- `queue`: Cola de trabajos esperando

### `Job`
Representa un trabajo con operaciones en secuencia.

```python
job = Job(job_id=0, operations=[(0, 5), (1, 3), (2, 4)])
```

**Atributos:**
- `id`: Identificador √∫nico
- `operations`: Lista de (machine_id, duration)
- `arrival_time`: Tiempo de llegada al sistema
- `completion_time`: Tiempo de finalizaci√≥n

### `MetricsCalculator`
Calcula m√©tricas de desempe√±o.

```python
calc = MetricsCalculator(log, jobs_data, due_dates)
metrics = calc.print_metrics(rule_name="SPT")
```

**M√©todos:**
- `calculate_makespan()`: Retorna el makespan
- `calculate_tardiness()`: Retorna (tardanza_total, tardanza_avg, count)
- `calculate_vip()`: Retorna VIP promedio
- `calculate_machine_utilization()`: Retorna utilizaci√≥n por m√°quina
- `get_all_metrics()`: Retorna diccionario con todas las m√©tricas

### `SchedulingRules`
Implementa reglas de despacho est√°ticas.

```python
ordered = SchedulingRules.SPT(jobs_data)
ordered = SchedulingRules.EDD(jobs_data, due_dates)
ordered = SchedulingRules.LPT(jobs_data)
```

**M√©todos est√°ticos:**
- `SPT()`: Shortest Processing Time
- `EDD()`: Earliest Due Date
- `LPT()`: Longest Processing Time
- `apply_rule()`: Aplica una regla y retorna orden

### `Datasets`
Gestiona datasets de benchmark.

```python
jobs, due_dates = Datasets.load_dataset("FT06")
Datasets.print_dataset_info(jobs, due_dates, "FT06")
```

**M√©todos est√°ticos:**
- `load_ft06()`: Carga FT06 (6x6)
- `load_ft10()`: Carga FT10 (10x10)
- `load_dataset()`: Carga un dataset por nombre
- `get_available_datasets()`: Lista datasets disponibles

---

## M√©tricas Explicadas

### Makespan
**Definici√≥n:** Tiempo total desde que comienza la simulaci√≥n hasta que se completa el √∫ltimo job.

**F√≥rmula:** `Makespan = max(completion_time)`

**Interpretaci√≥n:** Menor makespan = mejor eficiencia general

### Tardanza (Tardiness)
**Definici√≥n:** Suma de los atrasos respecto a las fechas de entrega.

**F√≥rmula:** `Tardiness = Œ£ max(0, completion_time - due_date)`

**Interpretaci√≥n:** Menor tardanza = menos jobs atrasados

### VIP (Work In Progress)
**Definici√≥n:** N√∫mero promedio de trabajos en proceso simult√°neamente.

**F√≥rmula:** `VIP = n√∫mero_de_jobs / makespan`

**Interpretaci√≥n:** Menor VIP = menos congesti√≥n en el sistema

### Utilizaci√≥n
**Definici√≥n:** Porcentaje de tiempo que cada m√°quina est√° ocupada.

**F√≥rmula:** `Utilizaci√≥n = (tiempo_ocupado / tiempo_total) √ó 100%`

**Interpretaci√≥n:** Mayor utilizaci√≥n = mejor uso de recursos

---

## Ejemplos de Uso Avanzado

### Ejemplo 1: Simular solo con FT10

```python
from simulator_static import run_validation

results = run_validation(dataset_name="FT10", verbose=True)
```

### Ejemplo 2: Simulaci√≥n con una sola regla

```python
from simulator_static import run_simulation
from datasets import Datasets

jobs, due_dates = Datasets.load_dataset("FT06")

result = run_simulation(
    jobs, 
    due_dates,
    rule="EDD",
    verbose=True,
    export_log=True
)

print(f"Makespan: {result['metrics']['makespan']}")
print(f"Tardanza: {result['metrics']['tardiness_total']}")
```

### Ejemplo 3: Acceder a los logs program√°ticamente

```python
from simulator_static import run_simulation
from datasets import Datasets
import pandas as pd

jobs, due_dates = Datasets.load_dataset("FT06")

result = run_simulation(jobs, due_dates, rule="SPT", export_log=False)

# Convertir log a DataFrame
df = pd.DataFrame(result["log"], columns=["time", "event", "job", "machine"])

# Filtrar eventos de inicio
start_events = df[df["event"] == "start"]
print(start_events)

# Agrupar por m√°quina
by_machine = df.groupby("machine")["time"].count()
print(by_machine)
```

---

## Notas Importantes

### ‚ö†Ô∏è Comportamiento Esperado en FT06
Las tres reglas (SPT, EDD, LPT) generan el mismo makespan porque el dataset FT06 es peque√±o y las restricciones de precedencia entre m√°quinas dominan m√°s que el orden de inicio. Este es un comportamiento **normal** en datasets constringidos.

### üìù Datos Generados
- Los archivos CSV se generan con timestamp para evitar sobrescrituras
- Cada simulaci√≥n crea un nuevo CSV con el log completo
- Los resultados de validaci√≥n se comparan en un √∫nico archivo

### üîß Personalizaci√≥n
Para agregar nuevos datasets, editar `datasets.py`:
```python
@staticmethod
def load_my_dataset() -> Tuple[List[List[Tuple[int, int]]], Dict[int, float]]:
    jobs = [...]  # tu dataset
    due_dates = {...}  # tus fechas de entrega
    return jobs, due_dates
```

---

## Pr√≥ximas Fases

- **Fase 2:** Extensi√≥n din√°mica (incorporar SPADE agents)
- **Fase 3:** Digital Twin con datos en tiempo real
- **Fase 4:** Integraci√≥n con JADE (tt_twin_scheduler_2025)

---

## Autor
**JOVILCHESC** - Noviembre 2025

## Licencia
Proyecto de investigaci√≥n en Scheduling Inteligente Multi-Agente
